{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#loading the Dataset into Data Frame\n",
    "Dataset = pd.read_csv('C:\\\\Users\\\\aksha\\\\Desktop\\\\Data Mining project\\\\creditcard_smote.csv')\n",
    "Dataset.loc[Dataset.Class == 0, 'Normal'] = 1\n",
    "Dataset.loc[Dataset.Class == 1, 'Normal'] = 0\n",
    "Dataset = Dataset.rename(columns={'Class': 'Fraud'})\n",
    "Dataset=Dataset.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#splitting the dataset into Training data set 70% and test dataset 30%\n",
    "trainlength=int(len(Dataset)*0.7)\n",
    "train_dataset=Dataset[0:trainlength]\n",
    "test_dataset=Dataset[trainlength:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Fraud</th>\n",
       "      <th>Normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>242033.000000</td>\n",
       "      <td>242033.000000</td>\n",
       "      <td>242033.000000</td>\n",
       "      <td>242033.000000</td>\n",
       "      <td>242033.000000</td>\n",
       "      <td>242033.000000</td>\n",
       "      <td>242033.000000</td>\n",
       "      <td>242033.000000</td>\n",
       "      <td>242033.000000</td>\n",
       "      <td>242033.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>242033.000000</td>\n",
       "      <td>242033.000000</td>\n",
       "      <td>242033.000000</td>\n",
       "      <td>242033.000000</td>\n",
       "      <td>242033.000000</td>\n",
       "      <td>242033.000000</td>\n",
       "      <td>242033.000000</td>\n",
       "      <td>242033.000000</td>\n",
       "      <td>242033.000000</td>\n",
       "      <td>242033.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>140840.672625</td>\n",
       "      <td>-0.035184</td>\n",
       "      <td>0.028533</td>\n",
       "      <td>-0.054880</td>\n",
       "      <td>0.044651</td>\n",
       "      <td>-0.028560</td>\n",
       "      <td>-0.009061</td>\n",
       "      <td>-0.053186</td>\n",
       "      <td>0.009489</td>\n",
       "      <td>-0.021782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>-0.003428</td>\n",
       "      <td>0.001384</td>\n",
       "      <td>-0.000456</td>\n",
       "      <td>0.002055</td>\n",
       "      <td>0.001103</td>\n",
       "      <td>88.344534</td>\n",
       "      <td>0.010945</td>\n",
       "      <td>0.989055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>82872.030295</td>\n",
       "      <td>2.084137</td>\n",
       "      <td>1.724099</td>\n",
       "      <td>1.761464</td>\n",
       "      <td>1.493049</td>\n",
       "      <td>1.490104</td>\n",
       "      <td>1.344724</td>\n",
       "      <td>1.482774</td>\n",
       "      <td>1.329876</td>\n",
       "      <td>1.142085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.736409</td>\n",
       "      <td>0.632774</td>\n",
       "      <td>0.606469</td>\n",
       "      <td>0.521619</td>\n",
       "      <td>0.481968</td>\n",
       "      <td>0.422106</td>\n",
       "      <td>0.331506</td>\n",
       "      <td>249.000328</td>\n",
       "      <td>0.104043</td>\n",
       "      <td>0.104043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-56.407510</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-48.325589</td>\n",
       "      <td>-5.600607</td>\n",
       "      <td>-113.743307</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-43.557242</td>\n",
       "      <td>-50.420090</td>\n",
       "      <td>-13.434066</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.499423</td>\n",
       "      <td>-36.666000</td>\n",
       "      <td>-2.836627</td>\n",
       "      <td>-8.696627</td>\n",
       "      <td>-2.604551</td>\n",
       "      <td>-22.565679</td>\n",
       "      <td>-15.430084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>68696.000000</td>\n",
       "      <td>-0.932059</td>\n",
       "      <td>-0.598040</td>\n",
       "      <td>-0.913705</td>\n",
       "      <td>-0.838536</td>\n",
       "      <td>-0.704801</td>\n",
       "      <td>-0.774094</td>\n",
       "      <td>-0.572114</td>\n",
       "      <td>-0.205835</td>\n",
       "      <td>-0.659661</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.539722</td>\n",
       "      <td>-0.163034</td>\n",
       "      <td>-0.356850</td>\n",
       "      <td>-0.315497</td>\n",
       "      <td>-0.326947</td>\n",
       "      <td>-0.070241</td>\n",
       "      <td>-0.052435</td>\n",
       "      <td>5.660000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>140242.000000</td>\n",
       "      <td>0.011084</td>\n",
       "      <td>0.072730</td>\n",
       "      <td>0.170239</td>\n",
       "      <td>-0.001349</td>\n",
       "      <td>-0.060316</td>\n",
       "      <td>-0.275666</td>\n",
       "      <td>0.030859</td>\n",
       "      <td>0.026472</td>\n",
       "      <td>-0.055169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007665</td>\n",
       "      <td>-0.012146</td>\n",
       "      <td>0.039607</td>\n",
       "      <td>0.018224</td>\n",
       "      <td>-0.051987</td>\n",
       "      <td>0.002097</td>\n",
       "      <td>0.011803</td>\n",
       "      <td>22.260000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>212668.100000</td>\n",
       "      <td>1.311258</td>\n",
       "      <td>0.819570</td>\n",
       "      <td>1.022268</td>\n",
       "      <td>0.778212</td>\n",
       "      <td>0.609256</td>\n",
       "      <td>0.398195</td>\n",
       "      <td>0.562093</td>\n",
       "      <td>0.335335</td>\n",
       "      <td>0.594547</td>\n",
       "      <td>...</td>\n",
       "      <td>0.530485</td>\n",
       "      <td>0.147882</td>\n",
       "      <td>0.436787</td>\n",
       "      <td>0.352081</td>\n",
       "      <td>0.241060</td>\n",
       "      <td>0.093828</td>\n",
       "      <td>0.080857</td>\n",
       "      <td>78.070000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>334610.000000</td>\n",
       "      <td>2.454930</td>\n",
       "      <td>22.057729</td>\n",
       "      <td>9.382558</td>\n",
       "      <td>16.875344</td>\n",
       "      <td>34.801666</td>\n",
       "      <td>73.301626</td>\n",
       "      <td>120.589494</td>\n",
       "      <td>19.303566</td>\n",
       "      <td>15.594995</td>\n",
       "      <td>...</td>\n",
       "      <td>8.361985</td>\n",
       "      <td>22.528412</td>\n",
       "      <td>4.584549</td>\n",
       "      <td>6.070850</td>\n",
       "      <td>3.517346</td>\n",
       "      <td>31.612198</td>\n",
       "      <td>33.847808</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0             V1             V2             V3  \\\n",
       "count  242033.000000  242033.000000  242033.000000  242033.000000   \n",
       "mean   140840.672625      -0.035184       0.028533      -0.054880   \n",
       "std     82872.030295       2.084137       1.724099       1.761464   \n",
       "min         1.000000     -56.407510     -72.715728     -48.325589   \n",
       "25%     68696.000000      -0.932059      -0.598040      -0.913705   \n",
       "50%    140242.000000       0.011084       0.072730       0.170239   \n",
       "75%    212668.100000       1.311258       0.819570       1.022268   \n",
       "max    334610.000000       2.454930      22.057729       9.382558   \n",
       "\n",
       "                  V4             V5             V6             V7  \\\n",
       "count  242033.000000  242033.000000  242033.000000  242033.000000   \n",
       "mean        0.044651      -0.028560      -0.009061      -0.053186   \n",
       "std         1.493049       1.490104       1.344724       1.482774   \n",
       "min        -5.600607    -113.743307     -26.160506     -43.557242   \n",
       "25%        -0.838536      -0.704801      -0.774094      -0.572114   \n",
       "50%        -0.001349      -0.060316      -0.275666       0.030859   \n",
       "75%         0.778212       0.609256       0.398195       0.562093   \n",
       "max        16.875344      34.801666      73.301626     120.589494   \n",
       "\n",
       "                  V8             V9      ...                  V22  \\\n",
       "count  242033.000000  242033.000000      ...        242033.000000   \n",
       "mean        0.009489      -0.021782      ...             0.000334   \n",
       "std         1.329876       1.142085      ...             0.736409   \n",
       "min       -50.420090     -13.434066      ...            -9.499423   \n",
       "25%        -0.205835      -0.659661      ...            -0.539722   \n",
       "50%         0.026472      -0.055169      ...             0.007665   \n",
       "75%         0.335335       0.594547      ...             0.530485   \n",
       "max        19.303566      15.594995      ...             8.361985   \n",
       "\n",
       "                 V23            V24            V25            V26  \\\n",
       "count  242033.000000  242033.000000  242033.000000  242033.000000   \n",
       "mean        0.000431      -0.003428       0.001384      -0.000456   \n",
       "std         0.632774       0.606469       0.521619       0.481968   \n",
       "min       -36.666000      -2.836627      -8.696627      -2.604551   \n",
       "25%        -0.163034      -0.356850      -0.315497      -0.326947   \n",
       "50%        -0.012146       0.039607       0.018224      -0.051987   \n",
       "75%         0.147882       0.436787       0.352081       0.241060   \n",
       "max        22.528412       4.584549       6.070850       3.517346   \n",
       "\n",
       "                 V27            V28         Amount          Fraud  \\\n",
       "count  242033.000000  242033.000000  242033.000000  242033.000000   \n",
       "mean        0.002055       0.001103      88.344534       0.010945   \n",
       "std         0.422106       0.331506     249.000328       0.104043   \n",
       "min       -22.565679     -15.430084       0.000000       0.000000   \n",
       "25%        -0.070241      -0.052435       5.660000       0.000000   \n",
       "50%         0.002097       0.011803      22.260000       0.000000   \n",
       "75%         0.093828       0.080857      78.070000       0.000000   \n",
       "max        31.612198      33.847808   25691.160000       1.000000   \n",
       "\n",
       "              Normal  \n",
       "count  242033.000000  \n",
       "mean        0.989055  \n",
       "std         0.104043  \n",
       "min         0.000000  \n",
       "25%         1.000000  \n",
       "50%         1.000000  \n",
       "75%         1.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#splitting the result class into categorical variables since output nodes are two\n",
    "#Also taking the result class into a saperate variable \n",
    "y_train=train_dataset.Fraud\n",
    "y_train = pd.concat([y_train, train_dataset.Normal], axis=1)\n",
    "y_test=test_dataset.Fraud\n",
    "y_test = pd.concat([y_test, test_dataset.Normal], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'Class'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-9db4d14d1bb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mClass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\aksha\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2670\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2671\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2672\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2673\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'Class'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#taking the classes out of \n",
    "train_dataset.drop(['Fraud'], axis = 1)\n",
    "train_dataset.drop(['Normal'], axis = 1)\n",
    "test_dataset.drop(['Fraud'], axis = 1)\n",
    "test_dataset.drop(['Normal'], axis = 1)\n",
    "features = train_dataset.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#converting data frames into matrix for Tensor operations\n",
    "features = train_dataset.columns.values\n",
    "input_x=train_dataset.as_matrix()\n",
    "input_y=y_train.as_matrix()\n",
    "test_x=test_dataset.as_matrix()\n",
    "test_y=y_test.as_matrix()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "input_nodes = 32\n",
    "mulitplier = 1.5 \n",
    "hidden_nodes1 = 15\n",
    "hidden_nodes2 = round(hidden_nodes1 * mulitplier)\n",
    "hidden_nodes3 = round(hidden_nodes2 * mulitplier)\n",
    "hidden_nodes4 = round(hidden_nodes3 * mulitplier)\n",
    "pkeep = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Defining Layers of neural network\n",
    "x = tf.placeholder(tf.float32, [None, input_nodes])\n",
    "\n",
    "# layer 1\n",
    "W1 = tf.Variable(tf.truncated_normal([input_nodes, hidden_nodes1], stddev = 0.15))\n",
    "b1 = tf.Variable(tf.zeros([hidden_nodes1]))\n",
    "y1 = tf.nn.sigmoid(tf.matmul(x, W1) + b1)\n",
    "\n",
    "# layer 2\n",
    "W2 = tf.Variable(tf.truncated_normal([hidden_nodes1, hidden_nodes2], stddev = 0.15))\n",
    "b2 = tf.Variable(tf.zeros([hidden_nodes2]))\n",
    "y2 = tf.nn.sigmoid(tf.matmul(y1, W2) + b2)\n",
    "\n",
    "# layer 3\n",
    "W3 = tf.Variable(tf.truncated_normal([hidden_nodes2, hidden_nodes3], stddev = 0.15)) \n",
    "b3 = tf.Variable(tf.zeros([hidden_nodes3]))\n",
    "y3 = tf.nn.sigmoid(tf.matmul(y2, W3) + b3)\n",
    "y3 = tf.nn.dropout(y3, pkeep)\n",
    "\n",
    "# layer 4\n",
    "W4 = tf.Variable(tf.truncated_normal([hidden_nodes3, hidden_nodes4], stddev = 0.15)) \n",
    "b4 = tf.Variable(tf.zeros([hidden_nodes4]))\n",
    "y4 = tf.nn.sigmoid(tf.matmul(y3, W4) + b4)\n",
    "y4 = tf.nn.dropout(y4, pkeep)\n",
    "\n",
    "# layer 5\n",
    "W5 = tf.Variable(tf.truncated_normal([hidden_nodes4, 2], stddev = 0.15)) \n",
    "b5= tf.Variable(tf.zeros([2]))\n",
    "y5 = tf.nn.softmax(tf.matmul(y4, W5) + b5)\n",
    "\n",
    "# output\n",
    "y = y5\n",
    "y_ = tf.placeholder(tf.float32, [None, 2])\n",
    "\n",
    "training_epochs = 10\n",
    "training_dropout = 0.9\n",
    "display_step = 1 \n",
    "n_samples = y_train.shape[0]\n",
    "batch_size = 2048\n",
    "learning_rate = 0.005\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cost function: Cross Entropy\n",
    "cost = -tf.reduce_sum(y_ * tf.log(y))\n",
    "\n",
    "# We will optimize our model via AdamOptimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Correct prediction if the most likely value (Fraud or Normal) from softmax equals the target value.\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "# AUC values for results\n",
    "auc, update_op = tf.contrib.metrics.streaming_auc(y, y_)\n",
    "recall,recall_op=tf.metrics.recall(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "#Confusion matrix for specificity calculations\n",
    "matrics=tf.confusion_matrix(tf.argmax(y,1), tf.argmax(y_,1)) \n",
    "# Calculate accuracy, precision, recall and F1 score.\n",
    "#fp=tf.metrics.false_positives(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "# confusion matrix manually \n",
    "#predictions = tf.argmax(y_, 1)\n",
    "#actuals = tf.argmax(y,1)\n",
    "\n",
    "#ones_like_actuals = tf.ones_like(actuals)\n",
    "#zeros_like_actuals = tf.zeros_like(actuals)\n",
    "#ones_like_predictions = tf.ones_like(predictions)\n",
    "#zeros_like_predictions = tf.zeros_like(predictions)\n",
    "\n",
    "#tp_op = tf.reduce_sum(\n",
    "#    tf.cast(\n",
    "#        tf.logical_and(\n",
    "#        tf.equal(actuals, ones_like_actuals), \n",
    "#        tf.equal(predictions, ones_like_predictions)\n",
    "#        ), \n",
    "#        \"float\"\n",
    "#    )\n",
    "#)\n",
    "\n",
    "#tn_op = tf.reduce_sum(\n",
    "#    tf.cast(\n",
    "#      tf.logical_and(\n",
    "#        tf.equal(actuals, zeros_like_actuals), \n",
    "#        tf.equal(predictions, zeros_like_predictions)\n",
    "#      ), \n",
    "#      \"float\"\n",
    "#    )\n",
    "#  )\n",
    "\n",
    "#fp_op = tf.reduce_sum(\n",
    "#    tf.cast(\n",
    "#      tf.logical_and(\n",
    "#        tf.equal(actuals, zeros_like_actuals), \n",
    "#        tf.equal(predictions, ones_like_predictions)\n",
    "#), \n",
    "#      \"float\"\n",
    "#    )\n",
    "#  )\n",
    "\n",
    "#fn_op = tf.reduce_sum(\n",
    "#    tf.cast(\n",
    "#      tf.logical_and(\n",
    "#        tf.equal(actuals, ones_like_actuals), \n",
    "#        tf.equal(predictions, zeros_like_predictions)\n",
    "#      ), \n",
    "#      \"float\"\n",
    "#    )\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "accuracy_summary = [] # Record accuracy values for plot\n",
    "cost_summary = [] # Record cost values for plot\n",
    "valid_accuracy_summary = [] \n",
    "valid_recall_summary=[]\n",
    "valid_cost_summary = [] \n",
    "stop_early = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Acc = 0.98906 train_Auc = 0.0 train_recall = 0.0 Cost = 14782.51562 Valid_Acc = 0.98927 valid_Auc = 0.989041 Valid_recall = 0.989055 Valid_specificity = 0.989270117325 Valid_Cost =  6151.87305\n",
      "Epoch: 1 Acc = 0.98906 train_Auc = 0.989094 train_recall = 0.98912 Cost = 14788.62793 Valid_Acc = 0.98927 valid_Auc = 0.989111 Valid_recall = 0.989093 Valid_specificity = 0.989270117325 Valid_Cost =  6156.58398\n",
      "Epoch: 2 Acc = 0.98906 train_Auc = 0.989145 train_recall = 0.98912 Cost = 14808.01953 Valid_Acc = 0.98927 valid_Auc = 0.98913 Valid_recall = 0.989103 Valid_specificity = 0.989270117325 Valid_Cost =  6157.03809\n",
      "Epoch: 3 Acc = 0.98906 train_Auc = 0.989151 train_recall = 0.98912 Cost = 14752.92090 Valid_Acc = 0.98927 valid_Auc = 0.98914 Valid_recall = 0.989107 Valid_specificity = 0.989270117325 Valid_Cost =  6157.14258\n",
      "Epoch: 4 Acc = 0.98906 train_Auc = 0.989155 train_recall = 0.98912 Cost = 14723.86230 Valid_Acc = 0.98927 valid_Auc = 0.989125 Valid_recall = 0.98911 Valid_specificity = 0.989270117325 Valid_Cost =  6156.36719\n",
      "Epoch: 5 Acc = 0.98906 train_Auc = 0.98913 train_recall = 0.98912 Cost = 14764.38574 Valid_Acc = 0.98927 valid_Auc = 0.989149 Valid_recall = 0.989112 Valid_specificity = 0.989270117325 Valid_Cost =  6155.31055\n",
      "Epoch: 6 Acc = 0.98906 train_Auc = 0.989153 train_recall = 0.98912 Cost = 14750.01562 Valid_Acc = 0.98927 valid_Auc = 0.989128 Valid_recall = 0.989113 Valid_specificity = 0.989270117325 Valid_Cost =  6153.82520\n",
      "Epoch: 7 Acc = 0.98906 train_Auc = 0.989132 train_recall = 0.98912 Cost = 14696.11914 Valid_Acc = 0.98927 valid_Auc = 0.989137 Valid_recall = 0.989114 Valid_specificity = 0.989270117325 Valid_Cost =  6148.63379\n",
      "Epoch: 8 Acc = 0.98906 train_Auc = 0.98914 train_recall = 0.98912 Cost = 14732.54199 Valid_Acc = 0.98927 valid_Auc = 0.989138 Valid_recall = 0.989115 Valid_specificity = 0.989270117325 Valid_Cost =  6154.10107\n",
      "Epoch: 9 Acc = 0.98906 train_Auc = 0.989141 train_recall = 0.98912 Cost = 14690.63672 Valid_Acc = 0.98927 valid_Auc = 0.989125 Valid_recall = 0.989115 Valid_specificity = 0.989270117325 Valid_Cost =  6154.31348\n",
      "\n",
      "Optimization Finished!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stop_early = 0 # To keep track of the number of epochs before early stopping\n",
    "\n",
    "# Save the best weights so that they can be used to make the final predictions\n",
    "#checkpoint = \"location_on_your_computer/best_model.ckpt\"\n",
    "saver = tf.train.Saver(max_to_keep=1)\n",
    "\n",
    "# Initialize variables and tensorflow session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.initialize_local_variables())\n",
    "    for epoch in range(training_epochs): \n",
    "        for batch in range(int(n_samples/batch_size)):\n",
    "            batch_x = input_x[batch*batch_size : (1+batch)*batch_size]\n",
    "            batch_y = input_y[batch*batch_size : (1+batch)*batch_size]\n",
    "\n",
    "            sess.run([optimizer], feed_dict={x: batch_x, \n",
    "                                             y_: batch_y,\n",
    "                                             pkeep: training_dropout})\n",
    "\n",
    "        # Display logs after every 10 epochs\n",
    "        if (epoch) % display_step == 0:\n",
    "            train_accuracy, newCost = sess.run([accuracy, cost], feed_dict={x: input_x, \n",
    "                                                                            y_: input_y,\n",
    "                                                                            pkeep: training_dropout})\n",
    "\n",
    "            valid_accuracy, valid_newCost = sess.run([accuracy, cost], feed_dict={x: test_x, \n",
    "                                                                                  y_: test_y,\n",
    "                                                                                  pkeep: 1})\n",
    "            train_recall,_ = sess.run([recall,recall_op],feed_dict={x: input_x, \n",
    "                                        y_: input_y,\n",
    "                                        pkeep: training_dropout})\n",
    "            train_auc,_=sess.run([auc,update_op],feed_dict={x: input_x, \n",
    "                                        y_: input_y,\n",
    "                                        pkeep: training_dropout})\n",
    "            valid_auc,_ = sess.run([auc,update_op], feed_dict={x: test_x, y_: test_y,pkeep: 1})\n",
    "            valid_recall,_ = sess.run([recall,recall_op], feed_dict={x: test_x, y_: test_y,pkeep: 1})\n",
    "            specificity=sess.run(matrics,feed_dict={x: test_x, y_: test_y,pkeep: 1})\n",
    "            #Specificity Calculation\n",
    "            tp=specificity[0][0]\n",
    "            fn=specificity[0][1]\n",
    "            fp=specificity[1][0]\n",
    "            tn=specificity[1][1]\n",
    "            spec=tn/(tn+fp)\n",
    "            print (\"Epoch:\", epoch,\n",
    "                   \"Acc =\", \"{:.5f}\".format(train_accuracy),\n",
    "                   \"train_Auc =\",train_auc,\n",
    "                   \"train_recall =\",train_recall,\n",
    "                   \"Cost =\", \"{:.5f}\".format(newCost),\n",
    "                   \"Valid_Acc =\", \"{:.5f}\".format(valid_accuracy), \n",
    "                   \"valid_Auc =\",valid_auc,\n",
    "                   \"Valid_recall =\",valid_recall,\n",
    "                   \"Valid_specificity =\",spec,\n",
    "                   \"Valid_Cost = \", \"{:.5f}\".format(valid_newCost))\n",
    "            \n",
    "            # Save the weights if these conditions are met.\n",
    "            #if epoch > 0 and valid_accuracy > max(valid_accuracy_summary) and valid_accuracy > 0.999:\n",
    "            #    saver.save(sess, checkpoint)\n",
    "            \n",
    "            # Record the results of the model\n",
    "            accuracy_summary.append(train_accuracy)\n",
    "            cost_summary.append(newCost)\n",
    "            valid_accuracy_summary.append(valid_accuracy)\n",
    "            valid_cost_summary.append(valid_newCost)\n",
    "           \n",
    "            \n",
    "            # If the model does not improve after 15 logs, stop the training.\n",
    "            if valid_accuracy < max(valid_accuracy_summary) and epoch > 100:\n",
    "                stop_early += 1\n",
    "                if stop_early == 15:\n",
    "                    break\n",
    "            else:\n",
    "                stop_early = 0\n",
    "            \n",
    "    print()\n",
    "    print(\"Optimization Finished!\")\n",
    "    print()   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
